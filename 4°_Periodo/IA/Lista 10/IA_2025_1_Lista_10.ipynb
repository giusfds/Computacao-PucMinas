{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNE63mOjvsIX"
      },
      "source": [
        "1) \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjXiISj8vwoh"
      },
      "source": [
        "**Perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RSMMxtu5vHE2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def perceptron(x, y, epochs=100, lr=0.1, random_state=None):\n",
        "    # Inicialização\n",
        "    n = len(x[0])\n",
        "    if random_state is not None:\n",
        "        random.seed(random_state)\n",
        "\n",
        "    weights = [random.uniform(-1, 1) for _ in range(n)]\n",
        "    b = random.uniform(-1, 1)\n",
        "    epoch = 0\n",
        "    output = []\n",
        "\n",
        "    while output != y and epoch < epochs:\n",
        "        output = []\n",
        "\n",
        "        for i in range(len(x)):\n",
        "            # Soma ponderada + bias\n",
        "            sum_w = sum(x[i][j] * weights[j] for j in range(n)) + b\n",
        "\n",
        "            # Função de ativação\n",
        "            found = 1 if sum_w > 0 else 0\n",
        "            output.append(found)\n",
        "\n",
        "            # Cálculo do erro\n",
        "            error = y[i] - found\n",
        "\n",
        "            # Ajuste de pesos\n",
        "            for j in range(n):\n",
        "                weights[j] += lr * error * x[i][j]\n",
        "            b += lr * error\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "        print(f\"\\nÉpoca {epoch}\")\n",
        "        print(f\"Pesos: {weights}\")\n",
        "        print(f\"Bias: {b}\")\n",
        "# perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkneX7D1vYS6"
      },
      "source": [
        "**Resolvendo AND, OR e XOR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gwRUQGw0vXR0"
      },
      "outputs": [],
      "source": [
        "entradas = [[0, 0], [0, 1], [1, 0], [1, 1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZumDtzczvcZ8"
      },
      "source": [
        "AND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbUrp6Kkvei4",
        "outputId": "97d9d231-58d3-44ad-cf76-1ca3c891c5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 1\n",
            "Pesos: [0.3788535969157675, -0.8499784895546662]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 2\n",
            "Pesos: [0.3788535969157675, -0.7499784895546662]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 3\n",
            "Pesos: [0.3788535969157675, -0.6499784895546662]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 4\n",
            "Pesos: [0.3788535969157675, -0.5499784895546662]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 5\n",
            "Pesos: [0.3788535969157675, -0.44997848955466624]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 6\n",
            "Pesos: [0.3788535969157675, -0.34997848955466626]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 7\n",
            "Pesos: [0.3788535969157675, -0.24997848955466626]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 8\n",
            "Pesos: [0.3788535969157675, -0.14997848955466625]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 9\n",
            "Pesos: [0.3788535969157675, -0.049978489554666244]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 10\n",
            "Pesos: [0.3788535969157675, 0.05002151044533376]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 11\n",
            "Pesos: [0.3788535969157675, 0.15002151044533377]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 12\n",
            "Pesos: [0.3788535969157675, 0.25002151044533377]\n",
            "Bias: -0.3499413632617615\n",
            "\n",
            "Época 13\n",
            "Pesos: [0.2788535969157675, 0.25002151044533377]\n",
            "Bias: -0.4499413632617615\n",
            "\n",
            "Época 14\n",
            "Pesos: [0.2788535969157675, 0.25002151044533377]\n",
            "Bias: -0.4499413632617615\n"
          ]
        }
      ],
      "source": [
        "saidas_and = [0, 0, 0, 1]\n",
        "perceptron(entradas, saidas_and, epochs=50, lr=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PmuTABGvgVK"
      },
      "source": [
        "OR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6xzZ93Wvg8I",
        "outputId": "48935d07-202e-4aa1-8fe5-c0831097d4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 1\n",
            "Pesos: [0.47885359691576745, -0.7499784895546662]\n",
            "Bias: -0.1499413632617615\n",
            "\n",
            "Época 2\n",
            "Pesos: [0.5788535969157674, -0.5499784895546662]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 3\n",
            "Pesos: [0.5788535969157674, -0.44997848955466624]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 4\n",
            "Pesos: [0.5788535969157674, -0.34997848955466626]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 5\n",
            "Pesos: [0.5788535969157674, -0.24997848955466626]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 6\n",
            "Pesos: [0.5788535969157674, -0.14997848955466625]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 7\n",
            "Pesos: [0.5788535969157674, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 8\n",
            "Pesos: [0.5788535969157674, 0.05002151044533376]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 9\n",
            "Pesos: [0.5788535969157674, 0.05002151044533376]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 10\n",
            "Pesos: [0.5788535969157674, 0.05002151044533376]\n",
            "Bias: -0.04994136326176149\n"
          ]
        }
      ],
      "source": [
        "saidas_or = [0, 1, 1, 1]\n",
        "perceptron(entradas, saidas_or, epochs=50, lr=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M0pOi6fvhhp"
      },
      "source": [
        "XOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9zwswDCvjXM",
        "outputId": "ca812b3c-2d6c-46d7-a84f-3ee0d4cfad7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Época 1\n",
            "Pesos: [0.3788535969157675, -0.8499784895546662]\n",
            "Bias: -0.2499413632617615\n",
            "\n",
            "Época 2\n",
            "Pesos: [0.3788535969157675, -0.7499784895546662]\n",
            "Bias: -0.1499413632617615\n",
            "\n",
            "Época 3\n",
            "Pesos: [0.3788535969157675, -0.6499784895546662]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 4\n",
            "Pesos: [0.3788535969157675, -0.5499784895546662]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 5\n",
            "Pesos: [0.3788535969157675, -0.44997848955466624]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 6\n",
            "Pesos: [0.2788535969157675, -0.44997848955466624]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 7\n",
            "Pesos: [0.2788535969157675, -0.34997848955466626]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 8\n",
            "Pesos: [0.1788535969157675, -0.34997848955466626]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 9\n",
            "Pesos: [0.1788535969157675, -0.24997848955466626]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 10\n",
            "Pesos: [0.07885359691576749, -0.24997848955466626]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 11\n",
            "Pesos: [0.07885359691576749, -0.14997848955466625]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 12\n",
            "Pesos: [-0.021146403084232518, -0.14997848955466625]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 13\n",
            "Pesos: [-0.021146403084232518, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 14\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: -0.04994136326176149\n",
            "\n",
            "Época 15\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 16\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 17\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 18\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 19\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 20\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 21\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 22\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 23\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 24\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 25\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 26\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 27\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 28\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 29\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 30\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 31\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 32\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 33\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 34\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 35\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 36\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 37\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 38\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 39\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 40\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 41\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 42\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 43\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 44\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 45\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 46\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 47\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 48\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 49\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n",
            "\n",
            "Época 50\n",
            "Pesos: [-0.12114640308423252, -0.049978489554666244]\n",
            "Bias: 0.050058636738238516\n"
          ]
        }
      ],
      "source": [
        "saidas_xor = [0, 1, 1, 0]\n",
        "perceptron(entradas, saidas_xor, epochs=50, lr=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO7aEPykv0NG"
      },
      "source": [
        "O problema do XOR não pode ser resolvido pelo perceptron porque este é um problema **não** linearmente separável."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAX2eC9WwH_R"
      },
      "source": [
        "**Explicação do Código**\n",
        "\n",
        "- Objetivo\n",
        "\n",
        "  A função `perceptron` implementa o algoritmo do perceptron simples, uma técnica clássica de aprendizado supervisionado usada para classificação binária linearmente separável.\n",
        "\n",
        "- Etapas do Algoritmo\n",
        "\n",
        "  1. **Inicialização**:\n",
        "\n",
        "    * Gera pesos (`weights`) e bias (`b`) aleatórios entre -1 e 1.\n",
        "    * O número de pesos corresponde ao número de atributos da entrada.\n",
        "\n",
        "  2. **Treinamento**:\n",
        "\n",
        "    * Para cada época:\n",
        "\n",
        "      * Percorre todas as entradas do conjunto de dados.\n",
        "      * Calcula a soma ponderada dos atributos mais o bias.\n",
        "      * Aplica a **função de ativação degrau binária**: `1` se a soma for maior que 0, `0` caso contrário.\n",
        "      * Compara a saída prevista com a saída esperada e calcula o erro.\n",
        "      * Atualiza os pesos e o bias com base no erro e na taxa de aprendizado.\n",
        "\n",
        "  3. **Condição de parada**:\n",
        "\n",
        "    * Para se a saída prevista for igual à saída desejada para todos os exemplos, ou se atingir o número máximo de épocas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2jPPtvKxGOl"
      },
      "source": [
        "2)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgMg38ypxUs5"
      },
      "source": [
        "**Backpropagation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "uAgODWB6xXTy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "# Função de ativação sigmoide e sua derivada\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def sigmoid_derivada(x):\n",
        "    return x * (1 - x)  # x já é a saída da sigmoide\n",
        "\n",
        "def inicializar_pesos(n_entrada, n_oculta, n_saida):\n",
        "    random.seed(42)  # reprodutibilidade\n",
        "\n",
        "    pesos_input_hidden = [[random.uniform(-1, 1) for _ in range(n_entrada)] for _ in range(n_oculta)]\n",
        "    bias_hidden = [random.uniform(-1, 1) for _ in range(n_oculta)]\n",
        "\n",
        "    pesos_hidden_output = [random.uniform(-1, 1) for _ in range(n_oculta)]\n",
        "    bias_output = random.uniform(-1, 1)\n",
        "\n",
        "    return pesos_input_hidden, bias_hidden, pesos_hidden_output, bias_output\n",
        "\n",
        "def mlp_backprop(x, y, n_oculta=2, epochs=10000, lr=0.5):\n",
        "    n_entrada = len(x[0])\n",
        "    n_saida = 1\n",
        "\n",
        "    # Inicialização dos pesos\n",
        "    w_ih, b_h, w_ho, b_o = inicializar_pesos(n_entrada, n_oculta, n_saida)\n",
        "\n",
        "    for epoca in range(epochs):\n",
        "        for i in range(len(x)):\n",
        "            # Forward Pass\n",
        "            entrada = x[i]\n",
        "            alvo = y[i]\n",
        "\n",
        "            # Camada oculta\n",
        "            soma_hidden = [sum(entrada[k] * w_ih[j][k] for k in range(n_entrada)) + b_h[j] for j in range(n_oculta)]\n",
        "            saida_hidden = [sigmoid(v) for v in soma_hidden]\n",
        "\n",
        "            # Camada de saída\n",
        "            soma_output = sum(saida_hidden[j] * w_ho[j] for j in range(n_oculta)) + b_o\n",
        "            saida_output = sigmoid(soma_output)\n",
        "\n",
        "            # Erro da saída\n",
        "            erro_saida = alvo - saida_output\n",
        "            delta_saida = erro_saida * sigmoid_derivada(saida_output)\n",
        "\n",
        "            # Erro da camada oculta\n",
        "            delta_hidden = [\n",
        "                sigmoid_derivada(saida_hidden[j]) * w_ho[j] * delta_saida\n",
        "                for j in range(n_oculta)\n",
        "            ]\n",
        "\n",
        "            # Atualização dos pesos (output)\n",
        "            for j in range(n_oculta):\n",
        "                w_ho[j] += lr * delta_saida * saida_hidden[j]\n",
        "            b_o += lr * delta_saida\n",
        "\n",
        "            # Atualização dos pesos (input -> hidden)\n",
        "            for j in range(n_oculta):\n",
        "                for k in range(n_entrada):\n",
        "                    w_ih[j][k] += lr * delta_hidden[j] * entrada[k]\n",
        "                b_h[j] += lr * delta_hidden[j]\n",
        "\n",
        "        # Imprimir erro médio a cada 1000 épocas\n",
        "        if epoca % 1000 == 0 or epoca == epochs - 1:\n",
        "            saidas_pred = []\n",
        "            for entrada in x:\n",
        "                soma_h = [sum(entrada[k] * w_ih[j][k] for k in range(n_entrada)) + b_h[j] for j in range(n_oculta)]\n",
        "                saida_h = [sigmoid(v) for v in soma_h]\n",
        "                soma_o = sum(saida_h[j] * w_ho[j] for j in range(n_oculta)) + b_o\n",
        "                saida_o = sigmoid(soma_o)\n",
        "                saidas_pred.append(round(saida_o))\n",
        "            print(f\"Época {epoca + 1} - Saída prevista: {saidas_pred}\")\n",
        "\n",
        "    # Resultados finais\n",
        "    print(\"\\n--- Resultado Final ---\")\n",
        "    for i in range(len(x)):\n",
        "        entrada = x[i]\n",
        "        soma_h = [sum(entrada[k] * w_ih[j][k] for k in range(n_entrada)) + b_h[j] for j in range(n_oculta)]\n",
        "        saida_h = [sigmoid(v) for v in soma_h]\n",
        "        soma_o = sum(saida_h[j] * w_ho[j] for j in range(n_oculta)) + b_o\n",
        "        saida_o = sigmoid(soma_o)\n",
        "        print(f\"Entrada: {entrada} -> Saída prevista: {round(saida_o)} (Esperado: {y[i]})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6O56UT6xeP1"
      },
      "source": [
        "**Resolvendo AND, OR e XOR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rLuQ2CtXxnrf"
      },
      "outputs": [],
      "source": [
        "entradas = [[0, 0], [0, 1], [1, 0], [1, 1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F49Hf0MLxiFC"
      },
      "source": [
        "AND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqhim_Fpxiv0",
        "outputId": "93ec56b0-8699-4d72-d7a3-6063b6064950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Época 1 - Saída prevista: [0, 0, 0, 0]\n",
            "Época 1001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 2001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 3001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 4001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 5001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 6001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 7001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 8001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 9001 - Saída prevista: [0, 0, 0, 1]\n",
            "Época 10000 - Saída prevista: [0, 0, 0, 1]\n",
            "\n",
            "--- Resultado Final ---\n",
            "Entrada: [0, 0] -> Saída prevista: 0 (Esperado: 0)\n",
            "Entrada: [0, 1] -> Saída prevista: 0 (Esperado: 0)\n",
            "Entrada: [1, 0] -> Saída prevista: 0 (Esperado: 0)\n",
            "Entrada: [1, 1] -> Saída prevista: 1 (Esperado: 1)\n"
          ]
        }
      ],
      "source": [
        "saidas_and = [0, 0, 0, 1]\n",
        "mlp_backprop(entradas, saidas_and, n_oculta=2, epochs=10000, lr=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IotJxcz5xi9J"
      },
      "source": [
        "OR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCVSjenexjvs",
        "outputId": "4a435a39-1c56-4a8e-e826-e1b32bf50ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Época 1 - Saída prevista: [1, 0, 1, 1]\n",
            "Época 1001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 2001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 3001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 4001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 5001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 6001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 7001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 8001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 9001 - Saída prevista: [0, 1, 1, 1]\n",
            "Época 10000 - Saída prevista: [0, 1, 1, 1]\n",
            "\n",
            "--- Resultado Final ---\n",
            "Entrada: [0, 0] -> Saída prevista: 0 (Esperado: 0)\n",
            "Entrada: [0, 1] -> Saída prevista: 1 (Esperado: 1)\n",
            "Entrada: [1, 0] -> Saída prevista: 1 (Esperado: 1)\n",
            "Entrada: [1, 1] -> Saída prevista: 1 (Esperado: 1)\n"
          ]
        }
      ],
      "source": [
        "saidas_or = [0, 1, 1, 1]\n",
        "mlp_backprop(entradas, saidas_or, n_oculta=2, epochs=10000, lr=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zglm_sPdxkJC"
      },
      "source": [
        "XOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWxUPnLoxk-Y",
        "outputId": "d4bf8391-5e77-496d-e373-a8545c526b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Época 1 - Saída prevista: [0, 0, 1, 0]\n",
            "Época 1001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 2001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 3001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 4001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 5001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 6001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 7001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 8001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 9001 - Saída prevista: [0, 1, 1, 0]\n",
            "Época 10000 - Saída prevista: [0, 1, 1, 0]\n",
            "\n",
            "--- Resultado Final ---\n",
            "Entrada: [0, 0] -> Saída prevista: 0 (Esperado: 0)\n",
            "Entrada: [0, 1] -> Saída prevista: 1 (Esperado: 1)\n",
            "Entrada: [1, 0] -> Saída prevista: 1 (Esperado: 1)\n",
            "Entrada: [1, 1] -> Saída prevista: 0 (Esperado: 0)\n"
          ]
        }
      ],
      "source": [
        "saidas_xor = [0, 1, 1, 0]\n",
        "mlp_backprop(entradas, saidas_xor, n_oculta=2, epochs=10000, lr=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t42g6ivx_E7"
      },
      "source": [
        "Investigando\n",
        "\n",
        "1. Por que a taxa de aprendizado é tão importante?\n",
        "\n",
        "A taxa de aprendizado é um hiperparâmetro essencial durante o treinamento de redes neurais. Ela determina o quão grande será o passo dado pelo otimizador (como o gradiente descendente) ao atualizar os pesos com base nos erros.\n",
        "\t•\tSe a taxa for muito baixa:\n",
        "\t•\tO treinamento será demorado, já que as atualizações nos pesos são mínimas.\n",
        "\t•\tPode acabar preso em mínimos locais ou demorar tanto que não converge em tempo hábil.\n",
        "\t•\tSe a taxa for muito alta:\n",
        "\t•\tO modelo pode ultrapassar o ponto ótimo, causando oscilações nos resultados.\n",
        "\t•\tEm casos extremos, pode até divergir e se tornar instável.\n",
        "\n",
        "⸻\n",
        "\n",
        "2. Qual o papel do bias (viés)?\n",
        "\n",
        "O bias é um termo adicional aplicado em cada neurônio. Ele desloca a função de ativação, dando mais flexibilidade à rede para ajustar os limites de decisão.\n",
        "\t•\tSem o bias:\n",
        "\t•\tA saída depende apenas da combinação linear entre pesos e entradas.\n",
        "\t•\tA função de ativação sempre passa pela origem, o que limita a capacidade da rede de aprender padrões complexos.\n",
        "\t•\tCom o bias:\n",
        "\t•\tA rede pode representar funções mais complexas, mesmo com uma arquitetura simples.\n",
        "\t•\tIsso melhora a adaptação da rede a diferentes tipos de dados.\n",
        "\n",
        "⸻\n",
        "\n",
        "3. Por que a função de ativação é essencial?\n",
        "\n",
        "A função de ativação introduz não-linearidade na rede, o que é crucial. Sem ela, mesmo redes profundas se comportariam como uma única função linear — incapazes de lidar com problemas como classificação não-linear ou funções como XOR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSfU92nlzlFX"
      },
      "source": [
        "Explicação do Código\n",
        "\n",
        "O código implementa o treinamento de uma rede neural simples com uma camada oculta, utilizando o algoritmo de backpropagation. O objetivo é aprender a função lógica XOR, que não pode ser resolvida por um perceptron de camada única, exigindo ao menos uma camada oculta para capturar a não-linearidade do problema.\n",
        "\n",
        "⸻\n",
        "\n",
        "Estrutura da Rede Neural\n",
        "\n",
        "A rede tem a seguinte configuração:\n",
        "\t1.\tCamada de entrada com 2 neurônios, representando os valores binários de entrada (0 ou 1);\n",
        "\t2.\tCamada oculta com 2 neurônios, responsável por aprender representações intermediárias;\n",
        "\t3.\tCamada de saída com 1 neurônio, que fornece a saída final da rede.\n",
        "\n",
        "⸻\n",
        "\n",
        "Funcionamento do Algoritmo\n",
        "\t1.\tInicialização de pesos e biases:\n",
        "\t•\tOs pesos (w1, w2) e os biases (b1, b2) são atribuídos aleatoriamente, com valores entre -1 e 1.\n",
        "\t•\tO número de neurônios na camada oculta é fixado em 2.\n",
        "\t•\tPode-se usar uma random_state para garantir reprodutibilidade nos testes.\n",
        "\t2.\tEscolha da função de ativação:\n",
        "\t•\tÉ possível alternar entre sigmoide e tangente hiperbólica (tanh).\n",
        "\t•\tAmbas são funções contínuas, não-lineares e com derivadas bem definidas — características ideais para o backpropagation.\n",
        "\t3.\tTreinamento (forward e backpropagation):\n",
        "\t•\tO processo é repetido por várias épocas, percorrendo cada exemplo da base XOR.\n",
        "Passo forward:\n",
        "\t•\tCalcula-se a combinação linear das entradas com os pesos da camada oculta, somando os biases.\n",
        "\t•\tAplica-se a função de ativação para obter a saída da camada oculta.\n",
        "\t•\tCom a saída da camada oculta, realiza-se o mesmo processo para gerar a saída final da rede.\n",
        "Cálculo do erro e backpropagation:\n",
        "\t•\tCalcula-se a diferença entre a saída da rede e o valor esperado.\n",
        "\t•\tEsse erro é propagado de volta para ajustar os pesos da camada de saída e depois da oculta.\n",
        "\t•\tAs atualizações são feitas com base no gradiente da função de ativação e escaladas pela taxa de aprendizado.\n",
        "\t4.\tTeste após o treinamento:\n",
        "\t•\tPor fim, a rede é testada com todas as combinações de entrada da função XOR.\n",
        "\t•\tOs resultados são impressos, mostrando as previsões feitas pela rede."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
